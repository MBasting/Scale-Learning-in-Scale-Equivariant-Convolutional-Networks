{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "%load_ext autoreload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markb/anaconda3/envs/flexconv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Load\n",
    "\n",
    "%autoreload\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ckconv_source = os.path.join(os.getcwd(), '../')\n",
    "\n",
    "if ckconv_source not in sys.path:\n",
    "    sys.path.append(ckconv_source)\n",
    "\n",
    "from ckconv.nn import ScaleFlexConv, ScaleCKConv, FlexConv\n",
    "import disco.ses_conv_learnable as SESN\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.utils import weight_norm\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import ckconv.nn as cknn\n",
    "\n",
    "import disco.ses_conv_learnable as SESN\n",
    "import utils.loaders as loaders\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Load all runs\n",
    "\n",
    "import pandas as pd \n",
    "import wandb\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import display\n",
    "api = wandb.Api()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def prepare_api_runs(runs, values = ['test/acc'], rounding=True):\n",
    "    combined = []\n",
    "    for run in runs: \n",
    "        temp_info_dict = run.summary._json_dict\n",
    "        # .summary contains the output keys/values for metrics like accuracy.\n",
    "        #  We call ._json_dict to omit large files \n",
    "        # .config contains the hyperparameters.\n",
    "        #  We remove special values that start with _.\n",
    "        temp_info_dict.update(run.config)\n",
    "        if isinstance(temp_info_dict['init_scales'], int) or isinstance(temp_info_dict['init_scales'], float):\n",
    "            temp_info_dict['init_scales'] = [temp_info_dict['init_scales']]\n",
    "        if rounding:\n",
    "            if temp_info_dict['sample_scales'][0] != 'DISCRETE':\n",
    "                temp_info_dict['sample_scales'] = str([round(sample_scale,3) for sample_scale in temp_info_dict['sample_scales'][1:]])\n",
    "            else:\n",
    "                temp_info_dict['sample_scales'] = str([round(sample_scale,3) for sample_scale in temp_info_dict['sample_scales'][1:]])\n",
    "            temp_info_dict['init_scales'] = str([round(init_scale,3) for init_scale in temp_info_dict['init_scales']])\n",
    "\n",
    "        else:\n",
    "            temp_info_dict['sample_scales'] = str(temp_info_dict['sample_scales'])\n",
    "            temp_info_dict['init_scales'] = str(temp_info_dict['init_scales'])\n",
    "        if 'test/acc' in temp_info_dict.keys():\n",
    "            temp_info_dict['Test Error'] = (1 - temp_info_dict['test/acc'])*100\n",
    "            temp_info_dict['val/acc.max'] = temp_info_dict['val/acc']['max']\n",
    "            combined.append(temp_info_dict)\n",
    "\n",
    "    return combined\n",
    "\n",
    "def plot_table(runs_in, name, indexes = ['sample_scales','init_scales'], values = ['Test Error'], rounding = True, Save=False):\n",
    "    # Prepare and load into dataframe\n",
    "    all_info = prepare_api_runs(runs_in, values)\n",
    "    df = pd.DataFrame.from_dict(all_info)\n",
    "    # display(df)\n",
    "\n",
    "    df = df.pivot_table(index=indexes, values=values, aggfunc=(np.mean, np.std))\n",
    "    # Save Df\n",
    "    if rounding:\n",
    "        df = df.astype(float).round(3)\n",
    "    df[r'Learned $\\sigma_{basis}$'] = df[\"Final Basis Min Scale\"][\"mean\"].astype('str') + \" (\"  + df[\"Final Basis Min Scale\"][\"std\"].astype('str') +\")\" \t\n",
    "    df['Learned ISR'] = df[\"Final ISR\"][\"mean\"].astype('str') + \" (\"  + df[\"Final ISR\"][\"std\"].astype('str') +\")\" \n",
    "\n",
    "    display(df)\n",
    "    if Save:\n",
    "        df.to_csv(f'results/{name}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does parameterization of learnable scales affect learnability of internal scales?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n",
    "We think that the way our internal scales are learned is a big reason why they are not collapsing, since the spacing logarithmically stays the same. We will compare a decoupled version of our learning strategy and directly learning the internal scales. \n",
    "\n",
    "We expect that especially directly learning the Internal Scales quickly leads to collapse. Why? This was also shown in a recent paper but we think that this parameterization makes the internal scales less dependent on each other and does not take into account Scale-Equivariance as much. \n",
    "\n",
    "## Network/Data\n",
    "Again, it remains unclear whether we want to use the full setup or want to compare the settings in a way more controlled setting like our toy network!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_641988/4073677325.py:23: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  df.drop(columns=[f'Scale {i+1} - 1'], inplace=True)\n",
      "/tmp/ipykernel_641988/4073677325.py:25: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  df.drop(columns=['Test Error 1',], inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Scale 1</th>\n",
       "      <th>Scale 2</th>\n",
       "      <th>Scale 3</th>\n",
       "      <th>Test Error</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data Range</th>\n",
       "      <th>learn_mode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">[1, 2.83]</th>\n",
       "      <th>2</th>\n",
       "      <td>1.965 $\\pm$ 0.047</td>\n",
       "      <td>3.5 $\\pm$ 0.193</td>\n",
       "      <td>6.235 $\\pm$ 0.497</td>\n",
       "      <td>2.321 $\\pm$ 0.095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.967 $\\pm$ 0.079</td>\n",
       "      <td>3.591 $\\pm$ 0.329</td>\n",
       "      <td>6.93 $\\pm$ 1.374</td>\n",
       "      <td>2.285 $\\pm$ 0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.96 $\\pm$ 0.081</td>\n",
       "      <td>3.608 $\\pm$ 0.435</td>\n",
       "      <td>6.672 $\\pm$ 1.311</td>\n",
       "      <td>2.291 $\\pm$ 0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">[1, 4.76]</th>\n",
       "      <th>2</th>\n",
       "      <td>1.865 $\\pm$ 0.046</td>\n",
       "      <td>3.357 $\\pm$ 0.105</td>\n",
       "      <td>6.45 $\\pm$ 0.049</td>\n",
       "      <td>2.554 $\\pm$ 0.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.996 $\\pm$ 0.013</td>\n",
       "      <td>3.626 $\\pm$ 0.158</td>\n",
       "      <td>6.83 $\\pm$ 0.167</td>\n",
       "      <td>2.565 $\\pm$ 0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.001 $\\pm$ 0.063</td>\n",
       "      <td>3.647 $\\pm$ 0.127</td>\n",
       "      <td>6.647 $\\pm$ 0.255</td>\n",
       "      <td>2.51 $\\pm$ 0.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">[1, 8]</th>\n",
       "      <th>2</th>\n",
       "      <td>1.689 $\\pm$ 0.109</td>\n",
       "      <td>3.262 $\\pm$ 0.107</td>\n",
       "      <td>6.997 $\\pm$ 0.282</td>\n",
       "      <td>3.057 $\\pm$ 0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.902 $\\pm$ 0.085</td>\n",
       "      <td>3.648 $\\pm$ 0.165</td>\n",
       "      <td>8.093 $\\pm$ 0.229</td>\n",
       "      <td>3.007 $\\pm$ 0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.943 $\\pm$ 0.063</td>\n",
       "      <td>3.977 $\\pm$ 0.053</td>\n",
       "      <td>8.145 $\\pm$ 0.057</td>\n",
       "      <td>2.872 $\\pm$ 0.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Scale 1            Scale 2  \\\n",
       "                                                              \n",
       "Data Range learn_mode                                         \n",
       "[1, 2.83]  2           1.965 $\\pm$ 0.047    3.5 $\\pm$ 0.193   \n",
       "           4           1.967 $\\pm$ 0.079  3.591 $\\pm$ 0.329   \n",
       "           6            1.96 $\\pm$ 0.081  3.608 $\\pm$ 0.435   \n",
       "[1, 4.76]  2           1.865 $\\pm$ 0.046  3.357 $\\pm$ 0.105   \n",
       "           4           1.996 $\\pm$ 0.013  3.626 $\\pm$ 0.158   \n",
       "           6           2.001 $\\pm$ 0.063  3.647 $\\pm$ 0.127   \n",
       "[1, 8]     2           1.689 $\\pm$ 0.109  3.262 $\\pm$ 0.107   \n",
       "           4           1.902 $\\pm$ 0.085  3.648 $\\pm$ 0.165   \n",
       "           6           1.943 $\\pm$ 0.063  3.977 $\\pm$ 0.053   \n",
       "\n",
       "                                 Scale 3         Test Error  \n",
       "                                                             \n",
       "Data Range learn_mode                                        \n",
       "[1, 2.83]  2           6.235 $\\pm$ 0.497  2.321 $\\pm$ 0.095  \n",
       "           4            6.93 $\\pm$ 1.374  2.285 $\\pm$ 0.038  \n",
       "           6           6.672 $\\pm$ 1.311  2.291 $\\pm$ 0.067  \n",
       "[1, 4.76]  2            6.45 $\\pm$ 0.049  2.554 $\\pm$ 0.093  \n",
       "           4            6.83 $\\pm$ 0.167  2.565 $\\pm$ 0.061  \n",
       "           6           6.647 $\\pm$ 0.255   2.51 $\\pm$ 0.084  \n",
       "[1, 8]     2           6.997 $\\pm$ 0.282  3.057 $\\pm$ 0.015  \n",
       "           4           8.093 $\\pm$ 0.229  3.007 $\\pm$ 0.049  \n",
       "           6           8.145 $\\pm$ 0.057   2.872 $\\pm$ 0.07  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "       &   &            Scale 1 &            Scale 2 &            Scale 3 &         Test Error \\\\\n",
      "       &   \\\\\n",
      "Data Range & learn_mode &                    &                    &                    &                    \\\\\n",
      "\\midrule\n",
      "[1, 2.83] & 2 &  1.965 $\\pm$ 0.047 &    3.5 $\\pm$ 0.193 &  6.235 $\\pm$ 0.497 &  2.321 $\\pm$ 0.095 \\\\\n",
      "       & 4 &  1.967 $\\pm$ 0.079 &  3.591 $\\pm$ 0.329 &   6.93 $\\pm$ 1.374 &  2.285 $\\pm$ 0.038 \\\\\n",
      "       & 6 &   1.96 $\\pm$ 0.081 &  3.608 $\\pm$ 0.435 &  6.672 $\\pm$ 1.311 &  2.291 $\\pm$ 0.067 \\\\\n",
      "[1, 4.76] & 2 &  1.865 $\\pm$ 0.046 &  3.357 $\\pm$ 0.105 &   6.45 $\\pm$ 0.049 &  2.554 $\\pm$ 0.093 \\\\\n",
      "       & 4 &  1.996 $\\pm$ 0.013 &  3.626 $\\pm$ 0.158 &   6.83 $\\pm$ 0.167 &  2.565 $\\pm$ 0.061 \\\\\n",
      "       & 6 &  2.001 $\\pm$ 0.063 &  3.647 $\\pm$ 0.127 &  6.647 $\\pm$ 0.255 &   2.51 $\\pm$ 0.084 \\\\\n",
      "[1, 8] & 2 &  1.689 $\\pm$ 0.109 &  3.262 $\\pm$ 0.107 &  6.997 $\\pm$ 0.282 &  3.057 $\\pm$ 0.015 \\\\\n",
      "       & 4 &  1.902 $\\pm$ 0.085 &  3.648 $\\pm$ 0.165 &  8.093 $\\pm$ 0.229 &  3.007 $\\pm$ 0.049 \\\\\n",
      "       & 6 &  1.943 $\\pm$ 0.063 &  3.977 $\\pm$ 0.053 &  8.145 $\\pm$ 0.057 &   2.872 $\\pm$ 0.07 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_641988/4073677325.py:27: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(df.to_latex(escape=False))\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "def visualize(runs, filter_scales = True):\n",
    "    # Prepare and load into dataframe\n",
    "    all_info = prepare_api_runs(runs, ['Test Error','Final ISR', 'Final Basis Min Scale'])\n",
    "    df = pd.DataFrame.from_dict(all_info)\n",
    "    # display(df)\n",
    "    df[r'Init \\sigma_{basis}'] = df['basis_min_scale']\n",
    "    df['Init ISR'] = df['ISR_start']\n",
    "    df['Data Range'] = df['sample_scales']\n",
    "    for i in range(3):\n",
    "        df[f'Scale {i+1}'] = df['Final Conv Scales'].apply(lambda x: x[i])\n",
    "    df = df.pivot_table(index=['Data Range', 'learn_mode'] , values=['Test Error','Scale 1','Scale 2','Scale 3'], aggfunc=(np.mean, np.std))\n",
    "    # Save Df\n",
    "    df = df.astype(float).round(3)\n",
    "    for i in range(3):\n",
    "        df[f'Scale {i+1} - 1'] = df[f'Scale {i+1}'][\"mean\"].astype('str') + r\" $\\pm$ \"  + df[f'Scale {i+1}'][\"std\"].astype('str')\n",
    "    # df[r'Learned $\\sigma_{basis}$'] = df[\"Final Basis Min Scale\"][\"mean\"].astype('str') + r\" $\\pm$ \"   + df[\"Final Basis Min Scale\"][\"std\"].astype('str') \t\n",
    "    # df['Learned ISR'] = df[\"Final ISR\"][\"mean\"].astype('str') + r\" $\\pm$ \"  + df[\"Final ISR\"][\"std\"].astype('str')\n",
    "    df['Test Error 1'] = df[\"Test Error\"][\"mean\"].astype('str') + r\" $\\pm$ \"  + df[\"Test Error\"][\"std\"].astype('str')\n",
    "    df.drop(columns=['Scale 1','Scale 2','Scale 3', 'Test Error'], inplace=True)\n",
    "    for i in range(3):\n",
    "        df[f'Scale {i+1}'] = df[f'Scale {i+1} - 1']\n",
    "        df.drop(columns=[f'Scale {i+1} - 1'], inplace=True)\n",
    "    df['Test Error'] = df['Test Error 1']\n",
    "    df.drop(columns=['Test Error 1',], inplace=True)\n",
    "    display(df)\n",
    "    print(df.to_latex(escape=False))\n",
    "\n",
    "\n",
    "api = wandb.Api()\n",
    "exp_name = 'Compare_Parameterization_Methods'\n",
    "# Load all runs\n",
    "\n",
    "runs = api.runs(f\"mbasting/scale_learning\", {\n",
    "        \"$and\": [{\"tags\": exp_name}]\n",
    "})\n",
    "visualize(runs, False)    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flexconv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
